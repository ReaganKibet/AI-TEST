2025-04-18 13:18:20,560 - root - INFO - ==================================================
2025-04-18 13:18:20,560 - root - INFO - Application starting up
2025-04-18 13:18:20,561 - root - INFO - Log file: logs/app_20250418_131820.log
2025-04-18 13:18:20,562 - root - INFO - ==================================================
2025-04-18 13:18:20,583 - root - INFO - Memory database initialized successfully
2025-04-18 13:18:20,602 - werkzeug - WARNING -  * Debugger is active!
2025-04-18 13:18:20,605 - werkzeug - INFO -  * Debugger PIN: 643-446-497
2025-04-18 13:19:51,171 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:19:51] "GET /swagger-ui/ HTTP/1.1" 200 -
2025-04-18 13:19:51,216 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:19:51] "GET /flask-apispec/static/swagger-ui.css HTTP/1.1" 200 -
2025-04-18 13:19:51,217 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:19:51] "GET /flask-apispec/static/swagger-ui-standalone-preset.js HTTP/1.1" 200 -
2025-04-18 13:19:51,219 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:19:51] "GET /flask-apispec/static/swagger-ui-bundle.js HTTP/1.1" 200 -
2025-04-18 13:19:51,359 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:19:51] "GET /swagger.json HTTP/1.1" 200 -
2025-04-18 13:19:51,464 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:19:51] "GET /flask-apispec/static/favicon-32x32.png HTTP/1.1" 200 -
2025-04-18 13:20:29,954 - root - INFO - Received prompt: show a lion in a park at night
2025-04-18 13:20:29,954 - root - INFO - Using default app IDs: ['f0997a01-d6d3-a5fe-53d8-561300318557', '69543f29-4d41-4afc-7f29-3d51591f11eb']
2025-04-18 13:20:32,058 - root - ERROR - [f0997a01-d6d3-a5fe-53d8-561300318557] Initialization failed: HTTPSConnectionPool(host='f0997a01-d6d3-a5fe-53d8-561300318557', port=443): Max retries exceeded with url: /manifest (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fae37e4ae00>: Failed to resolve 'f0997a01-d6d3-a5fe-53d8-561300318557' ([Errno -2] Name or service not known)"))
2025-04-18 13:20:34,091 - root - ERROR - [69543f29-4d41-4afc-7f29-3d51591f11eb] Initialization failed: HTTPSConnectionPool(host='69543f29-4d41-4afc-7f29-3d51591f11eb', port=443): Max retries exceeded with url: /manifest (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7fae37e4b5b0>: Failed to resolve '69543f29-4d41-4afc-7f29-3d51591f11eb' ([Errno -2] Name or service not known)"))
2025-04-18 13:20:34,091 - root - INFO - Processing prompt through pipeline
2025-04-18 13:20:34,106 - root - INFO - Enhancing prompt: show a lion in a park at night
2025-04-18 13:20:34,106 - root - INFO - Loading LLM model: gpt2 on cpu
2025-04-18 13:20:40,601 - root - INFO - Available RAM: 6.29 GB
2025-04-18 13:20:40,602 - root - INFO - Using 4-bit quantization for model
2025-04-18 13:20:40,618 - root - WARNING - bitsandbytes not available, skipping 4-bit quantization
2025-04-18 13:20:40,619 - root - INFO - Using 8-bit quantization for model
2025-04-18 13:20:41,171 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-04-18 13:21:25,669 - root - ERROR - Failed to initialize Transformers model: No module named 'scipy'
Traceback (most recent call last):
  File "/app/app/llm_manager.py", line 159, in _initialize_transformers_model
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 484, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py", line 2685, in from_pretrained
    from .utils.bitsandbytes import get_keys_to_not_convert, replace_with_bnb_linear
  File "/usr/local/lib/python3.10/site-packages/transformers/utils/bitsandbytes.py", line 11, in <module>
    import bitsandbytes as bnb
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py", line 8, in <module>
    from .adagrad import Adagrad, Adagrad8bit, Adagrad32bit
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/optim/adagrad.py", line 5, in <module>
    from bitsandbytes.optim.optimizer import Optimizer1State
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py", line 12, in <module>
    import bitsandbytes.functional as F
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/functional.py", line 12, in <module>
    from scipy.stats import norm
ModuleNotFoundError: No module named 'scipy'
2025-04-18 13:21:25,683 - root - ERROR - Failed to initialize LLM: No module named 'scipy'
Traceback (most recent call last):
  File "/app/app/llm_manager.py", line 75, in initialize
    self._initialize_transformers_model()
  File "/app/app/llm_manager.py", line 159, in _initialize_transformers_model
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 484, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py", line 2685, in from_pretrained
    from .utils.bitsandbytes import get_keys_to_not_convert, replace_with_bnb_linear
  File "/usr/local/lib/python3.10/site-packages/transformers/utils/bitsandbytes.py", line 11, in <module>
    import bitsandbytes as bnb
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py", line 8, in <module>
    from .adagrad import Adagrad, Adagrad8bit, Adagrad32bit
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/optim/adagrad.py", line 5, in <module>
    from bitsandbytes.optim.optimizer import Optimizer1State
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py", line 12, in <module>
    import bitsandbytes.functional as F
  File "/usr/local/lib/python3.10/site-packages/bitsandbytes/functional.py", line 12, in <module>
    from scipy.stats import norm
ModuleNotFoundError: No module named 'scipy'
2025-04-18 13:21:25,685 - root - WARNING - Initializing fallback model (GPT-2 small)
2025-04-18 13:21:32,026 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-04-18 13:22:14,844 - root - INFO - Fallback model initialized successfully
2025-04-18 13:22:14,871 - root - ERROR - Error enhancing prompt: "LayerNormKernelImpl" not implemented for 'Half'
Traceback (most recent call last):
  File "/app/app/llm_manager.py", line 230, in enhance_prompt
    output = self.pipe(input_text, max_new_tokens=256, temperature=0.7)
  File "/usr/local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py", line 201, in __call__
    return super().__call__(text_inputs, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/transformers/pipelines/base.py", line 1120, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/usr/local/lib/python3.10/site-packages/transformers/pipelines/base.py", line 1127, in run_single
    model_outputs = self.forward(model_inputs, **forward_params)
  File "/usr/local/lib/python3.10/site-packages/transformers/pipelines/base.py", line 1026, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
  File "/usr/local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py", line 263, in _forward
    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py", line 1572, in generate
    return self.sample(
  File "/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py", line 2619, in sample
    outputs = self(
  File "/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1080, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 903, in forward
    outputs = block(
  File "/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 390, in forward
    hidden_states = self.ln_1(hidden_states)
  File "/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/usr/local/lib/python3.10/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: "LayerNormKernelImpl" not implemented for 'Half'
2025-04-18 13:22:14,874 - root - INFO - Generating image from prompt: show a lion in a park at night with dramatic lighting, detailed textures, and vibrant colors
2025-04-18 13:22:14,875 - root - ERROR - Error in pipeline: Input schema not found for app ID: f0997a01-d6d3-a5fe-53d8-561300318557
2025-04-18 13:22:14,876 - root - ERROR - Pipeline error: Input schema not found for app ID: f0997a01-d6d3-a5fe-53d8-561300318557
2025-04-18 13:22:14,877 - root - INFO - Response prepared: 90 characters
2025-04-18 13:22:14,878 - werkzeug - INFO - 172.21.0.1 - - [18/Apr/2025 13:22:14] "POST /execute HTTP/1.1" 200 -
